{% extends 'base.html' %}
{% load static %}
{% block subtitle %}
    <span>guidelines</span>
{% endblock %}
{% block content %}
    <div id="background" class="centered">
    <fieldset>
        <legend><h1>MoonDiff Background</h1></legend>
        <p>MoonDiff serves up "before-and-after" pictures of the moon, taken from orbiting spacecraft decades apart. Volunteers then compare those pictures to discover the differences. Their discoveries teach us about the Moon's dynamic surface, and contribute to lunar exploration.</p>
        <h1>The big idea</h1>
        <p>There&rsquo;s a lot happening at the surface of Earth&rsquo;s Moon. Space rocks hit and blast new craters. Rocks break off and roll down hills. Spaceships land. Spaceships crash. Planetary scientists are still working on important questions, like:</p>
        <ul>
            <li>What&rsquo;s the meteorite impact cratering rate? How much space rock hits the moon per unit time?</li>
            <li>Where are the missing spacecraft crash sites? On <a href="https://nssdc.gsfc.nasa.gov/planetary/lunar/lunar_artifact_impacts.html" target="_blank" rel="noopener">this table of landing sites and crash sites</a>, we&rsquo;re still looking for all of the things in the red rows.</li>
            <li>What kind of geologic changes are happening right now on the lunar surface?</li>
        </ul>
        <p>One way to keep track of what&rsquo;s going on over there is to compare old and new images from the various cameras that have orbited the Moon (another way is to <a href="https://britastro.org/section_information_/lunar-section-overview/lunar-section-observation-activities/lunar-geological-change-detection/observing-lunar-impact-flashes" target="_blank" rel="noopener">watch, from Earth, for flashes</a>). From 2009 until today (February 2023), the Lunar Reconnaissance Orbiter (LRO) has continuously delivered amazing imagery, with resolution as high as half a meter ground sampling distance. To create before-and-after imagery spanning many years, the LRO team has carefully re-flown old images with the same lighting and spacecraft look angles, and <a href="https://doi.org/10.1038/nature19829" target="_blank" rel="noopener">found 222 new impact craters</a> in that 14-year dataset.</p>
        <p>We can look back in time much further than 2009, but it&rsquo;ll take some elbow grease, and that&rsquo;s where MoonDiff comes in. We have images covering 99% of the moon from the five 1966-1967 Lunar Orbiter (LO, not to be confused with LRO) missions. LO photographed selected areas in high resolution; as high as 2m ground sampling distance. A far cry from LRO&rsquo;s digital cameras, the LO cameras exposed film, developed it onboard, and then used an analog scanner to read it and transmit it back to Earth, where the radio signals were recorded on analog magnetic tape. Starting in 2008, a coalition of volunteer enthusiasts and private companies called the Lunar Orbiter Image Recovery Project (LOIRP) worked with NASA to digitize the images, rescuing them from their degrading magnetic tapes.</p>
        <p>The LRO team was able to use algorithms to automatically compare their before-and-after images, but that won&rsquo;t work with LO images. The LRO-LRO pairs share geometry and lighting, and benefit from 2009-era camera and avionics technology. Even given all that, they still had humans go through the automatic detections to remove false positives and classify the detected changes.</p>
        <p>So, we need brains ðŸ§Ÿ. MoonDiff seeks to compare the 60s-era LO images to recent LRO images. This means comparing images that are taken from different angles, and in different lighting. Additionally, they have relatively poor spatial control. Doing change detection between image pairs like that is beyond the capabilities of today&rsquo;s cleverest software. So, MoonDiff wields the best available tool for the job: the human brain&rsquo;s vision system.</p>
        <h1>Image preparation</h1>
        <p>The MoonDiff committee has to do quite a bit of prep work on the image pairs before they&rsquo;re ready for the community of MoonDiffers to do the comparison work. To begin with, we focused on the areas where the highest-resolution Lunar Orbiter data is available, shown in red here:</p>
        <img src="{% static 'lo_highres_ftpts.jpg' %}">
        <p>We&rsquo;ve been preparing images from these clusters of high-res LO images one cluster at a time. Although we&rsquo;ve been iterating on these methods, here&rsquo;s how it worked for our initial image set (34 pairs), which we&rsquo;re calling MoonDiffImgSet1:</p>
        <ol>
            <li><strong>Select pairs.</strong> We choose one cluster of the high-resolution LO images to work on at a time (between 9 and 16 LO images). Using <a href="https://ode.rsl.wustl.edu/moon/datafile/derived_products/coverageshapefiles/moon/" target="_blank" rel="noopener">image footprints and metadata from the Orbital Data Explorer</a> and some python code (not yet in the <a href="https://github.com/nasa-jpl/moondiff" target="_blank" rel="noopener">MoonDiff repository</a> but will be soon), we find all of the LRO Narrow Angle Camera images that overlap the LO images. We then rank them using a &ldquo;goodness metric&rdquo; we created, which combines three factors:</li>
            <ol>
                <li>The size of the overlap area</li>
                <li>The difference in phase angle</li>
                <li>The difference in solar incidence angle</li>
            </ol>
        </ol>
        <p>Finally, one of us manually chooses a set of LRO-LO pairs from that list which covers the LO cluster area at least once over. For each pair, we produce a finder plot like the below:</p>
        <img src="{% static 'ftpt_pair.png' %}">
        <p>This image shows a cluster of LO 24&rdquo; camera image footprints in light red, with LRO NAC image footprints in light blue. The particular pair in question (LO image 5117_HIGH_RES_2 with LRO NAC image M1114191668LE) is shown in bolded red and blue.</p>
        <ol>
            <li><strong>Retrieve and project raw images.</strong> Once we know which pairs we want to work with, we download Engineering Data Record (EDR) image files from the <a href="http://pds-geosciences.wustl.edu/geocopy/imaging/lunar_orbiter/" target="_blank" rel="noopener">Planetary Data System Geosciences Node</a> in for LO and from the <a href="https://pds.lroc.asu.edu/data/" target="_blank" rel="noopener">LROC PDS archive</a> for LO and use <a href="https://isis.astrogeology.usgs.gov/7.0.0/index.html" target="_blank" rel="noopener">USGS ISIS</a> to turn them into map-projected geospatial images. We project everything to IAU2000:30110 with 1m pixel spacing. LRO images are projected onto a lunar elevation model based on stereo reconstructions from the LRO Wide Angle Camera. Due to position uncertainty, we do not use an elevation model for LO images; for that projection we model the moon as a sphere.</li>
            <li><strong>Coregister the images.</strong> At this point, we have pairs of map-projected imagery, but it doesn&rsquo;t line up. Typically, if you locate a feature in the LRO image, the same feature will appear several kilometers away on the corresponding LO image. We try to fix this:</li>
            <ol>
                <li>Using ISIS qview, a moondiff committee member manually picks two pairs of corresponding points. Using those points, we translate and scale the LO image to roughly match the LRO image.</li>
                <li>Using algorithms in the Planetary Orbital Mosaicking and Mapping Toolset (<a href="https://www.hou.usra.edu/meetings/lpsc2023/pdf/1261.pdf" target="_blank" rel="noopener">POMM</a>), we find corresponding features within the image pair, and warp the LO image to match the LRO image. This attempts to remove internal distortions within the LO image, both from imprecision in the spacecraft positioning and from the reconstruction process in which strips of tape were combined by hand. We roughly assess the quality of the coregistration with a root-mean-square pixel offset value, which is greater than 10 pixels for some difficult pairs but less than 1 pixel for most.</li>
            </ol>
        </ol>
        <h1>Change detection and review</h1>
        <p>Here&rsquo;s where the public gets involved. Using the MoonDiff Comparer web app, people from around the world visually review our coregistered &ldquo;before and after&rdquo; image pairs. They can compare the images side-by-side, or by blinking or fading between the images. Our moon sleuths draw a polygon around areas where they see that something has changed between the two images.</p>
        <p>Lunar experts review each identified change using the MoonDiff Reviewer web app. Discoveries will be written up as scientific journal papers. Anyone involved in the process will be credited, either as an author, or in acknowledgements.</p>
        <h1>Citizen science</h1>
        <p>MoonDiff is made possible by <a href="https://nspires.nasaprs.com/external/solicitations/summary!init.do?solId=A08B277F1BFE46633E6FC178EBA87C8C&amp;stack=redirect" target="_blank" rel="noopener">NASA&rsquo;s Citizen Science Seed Funding Program</a> (proposal 21-CSSFP21-0016).</p>
        <p>NASA funds tons of other great citizen science projects. <a href="https://science.nasa.gov/citizenscience">Check them out here.</a></p>
    </fieldset>
    </div>
{% endblock content %}